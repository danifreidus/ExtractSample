{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec09487-55fb-46b9-b435-f08751511ea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'voila'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, clear_output\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvoila\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Store profile entries\u001b[39;00m\n\u001b[0;32m      7\u001b[0m profiles \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'voila'"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import voila\n",
    "\n",
    "# Store profile entries\n",
    "profiles = []\n",
    "\n",
    "# Output area for profile table\n",
    "profile_out = widgets.Output()\n",
    "\n",
    "layout = widgets.Layout(width='400px')  # Wider total box if needed\n",
    "style = {'description_width': '150px'}  # Wider label\n",
    "\n",
    "# Input widgets\n",
    "account_name = widgets.Text(description='Brand Name:', layout=layout, style=style)\n",
    "fb_name = widgets.Text(description='Facebook Handle:', layout=layout, style=style)\n",
    "inst_name = widgets.Text(description='Instagram Handle:', layout=layout, style=style)\n",
    "tt_name = widgets.Text(description='TikTok Handle:', layout=layout, style=style)\n",
    "\n",
    "# Button to add profile\n",
    "add_button = widgets.Button(description='Add Profile', button_style='primary')\n",
    "clear_button = widgets.Button(description='Clear All', button_style='warning')\n",
    "\n",
    "# Display profiles\n",
    "def display_profiles():\n",
    "    profile_out.clear_output()\n",
    "    if profiles:\n",
    "        df = pd.DataFrame(profiles)\n",
    "        with profile_out:\n",
    "            display(df)\n",
    "\n",
    "# Button click logic\n",
    "def on_add_clicked(_):\n",
    "    profiles.append({\n",
    "        'account_name': account_name.value.strip(),\n",
    "        'fb_profile_name': fb_name.value.strip(),\n",
    "        'inst_profile_name': inst_name.value.strip(),\n",
    "        'tt_profile_name': tt_name.value.strip()\n",
    "    })\n",
    "    account_name.value = fb_name.value = inst_name.value = tt_name.value = ''\n",
    "    display_profiles()\n",
    "\n",
    "def on_clear_clicked(_):\n",
    "    profiles.clear()\n",
    "    profile_out.clear_output()\n",
    "\n",
    "add_button.on_click(on_add_clicked)\n",
    "clear_button.on_click(on_clear_clicked)\n",
    "\n",
    "# Layout for inputs\n",
    "input_box = widgets.VBox([\n",
    "    account_name, fb_name, inst_name, tt_name,\n",
    "    widgets.HBox([add_button, clear_button]),\n",
    "    profile_out\n",
    "])\n",
    "\n",
    "display(widgets.HTML(\"<h2>ðŸ“‹ Enter Social Media Profiles</h2>\"))\n",
    "display(input_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8db828-b852-410a-aa49-e6980ed9fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "           \n",
    "    # ## Preparation\n",
    "    \n",
    "    # In[36]:\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    from apify_client import ApifyClient\n",
    "    import json\n",
    "    pd.options.display.max_columns = None\n",
    "    from datetime import datetime, timedelta, date\n",
    "    from pandas import json_normalize\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sqlalchemy.exc import DatabaseError\n",
    "    from openai import OpenAI, AsyncOpenAI\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas()\n",
    "    from typing import Dict, List\n",
    "    import tiktoken\n",
    "    import nest_asyncio, asyncio\n",
    "    import dateparser\n",
    "    import plotly\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    import matplotlib.ticker as ticker\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    from PIL import Image\n",
    "    from docx import Document\n",
    "    from docx.shared import Inches\n",
    "    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "    from docx.shared import Inches, Pt\n",
    "    from docx.oxml.ns import qn\n",
    "    from docx.oxml import OxmlElement\n",
    "    from docx.enum.table import WD_ALIGN_VERTICAL\n",
    "    from docx.shared import Pt, RGBColor\n",
    "    from io import BytesIO\n",
    "    from docx2pdf import convert\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    from IPython.display import FileLink\n",
    "    print('Run Started')\n",
    "    import pathlib\n",
    "    \n",
    "    \n",
    "    # ### API Keys\n",
    "    \n",
    "    # In[27]:\n",
    "    \n",
    "    \n",
    "    apify = ApifyClient(\"apify_api_KP7TYMkOEwszNWMuGjWqm8cUeAxoFs2pvmJF\")\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    \n",
    "    # ### Profile Names\n",
    "    \n",
    "    # In[5]:\n",
    "    \n",
    "    \n",
    "    # Create Lookup Table\n",
    "    lookup = []\n",
    "    for profile in profiles:\n",
    "        for platform, key in {\n",
    "            'Facebook': 'fb_profile_name',\n",
    "            'Instagram': 'inst_profile_name',\n",
    "            'Tiktok': 'tt_profile_name',\n",
    "        }.items():\n",
    "            lookup.append({\n",
    "                'platform': platform,\n",
    "                'user_name': profile[key],\n",
    "                'account_name': profile['account_name']\n",
    "            })\n",
    "    \n",
    "    lookup_df = pd.DataFrame(lookup)\n",
    "    lookup_df['user_name'] = lookup_df['user_name'].str.lower()\n",
    "    \n",
    "    \n",
    "    # In[6]:\n",
    "    \n",
    "    \n",
    "    # Collect every non-empty Facebook profile name\n",
    "    fb_profile_names = [\n",
    "        p[\"fb_profile_name\"]\n",
    "        for p in profiles\n",
    "        if p.get(\"fb_profile_name\")        # skips None or missing/empty entries\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # In[7]:\n",
    "    \n",
    "    \n",
    "    # Collect every non-empty Instagram profile name\n",
    "    inst_profile_names = [\n",
    "        p[\"inst_profile_name\"]\n",
    "        for p in profiles\n",
    "        if p.get(\"inst_profile_name\")        # skips None or missing/empty entries\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # In[8]:\n",
    "    \n",
    "    \n",
    "    # Collect every non-empty TikTok profile name\n",
    "    tt_profile_names = [\n",
    "        p[\"tt_profile_name\"]\n",
    "        for p in profiles\n",
    "        if p.get(\"tt_profile_name\")        # skips None or missing/empty entries\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # In[9]:\n",
    "    \n",
    "    \n",
    "    # Collect every non-empty YouTube profile name\n",
    "    yt_profile_names = [\n",
    "        p[\"yt_profile_name\"]\n",
    "        for p in profiles\n",
    "        if p.get(\"yt_profile_name\")        # skips None or missing/empty entries\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # In[10]:\n",
    "    \n",
    "    \n",
    "    # Collect every non-empty X profile name\n",
    "    x_profile_names = [\n",
    "        p[\"x_profile_name\"]\n",
    "        for p in profiles\n",
    "        if p.get(\"x_profile_name\")        # skips None or missing/empty entries\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # ### Global Parameters\n",
    "    \n",
    "    # In[11]:\n",
    "    \n",
    "    \n",
    "    max_results = 500\n",
    "    past_days_posts = 14 #Change to 3 after initial run\n",
    "    #past_days_comments = 3 #Change to 3 after initial run\n",
    "    \n",
    "    start_date_posts = (datetime.now() + timedelta(-past_days_posts)).strftime(\"%Y-%m-%d\")\n",
    "    #start_date_comments = (datetime.now() + timedelta(-past_days_comments)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    \n",
    "    # In[38]:\n",
    "    \n",
    "    \n",
    "    # Set smoother font globally\n",
    "    matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    \n",
    "    \n",
    "    # ## Posts\n",
    "    \n",
    "    # ### Facebook\n",
    "    \n",
    "    # In[12]:\n",
    "    \n",
    "    \n",
    "    # Facebook Parameters\n",
    "    \n",
    "    fb_max_results = max_results\n",
    "    fb_start_date_posts = start_date_posts\n",
    "    \n",
    "    \n",
    "    # In[13]:\n",
    "    \n",
    "    if fb_profile_names:\n",
    "        starturls = [f\"https://www.facebook.com/{name}/\" for name in fb_profile_names]\n",
    "        i = 0\n",
    "        data = {}\n",
    "        \n",
    "        for url in starturls:\n",
    "        \n",
    "            run_input = {\n",
    "        \n",
    "                \"page_url\": url,\n",
    "                \"start_date\": fb_start_date_posts,\n",
    "                \"max_posts\": fb_max_results\n",
    "            }\n",
    "        \n",
    "            # Run the Actor and wait for it to finish\n",
    "            run = apify.actor(\"danek/facebook-pages-posts-ppr\").call(run_input=run_input)\n",
    "        \n",
    "        \n",
    "            for item in apify.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "                data[i] = item\n",
    "                i = i + 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # In[14]:\n",
    "        \n",
    "        \n",
    "        posts = pd.DataFrame(data).transpose()\n",
    "        posts['facebookUrl'] = posts['author'].apply(lambda x: x.get('url') if isinstance(x, dict) else None)\n",
    "        posts['pageName'] = posts['facebookUrl'].str.extract(r'facebook\\.com/([^/?#]+)')\n",
    "        posts['time'] = pd.to_datetime(posts['timestamp'], unit='s', utc=True)\n",
    "        posts['time'] = posts['time'].dt.tz_convert('Africa/Johannesburg') \n",
    "        posts['likes'] = posts['reactions'].apply(lambda x: x.get('likes') if isinstance(x, dict) else None)\n",
    "        posts['isVideo'] = np.where(posts['video'].isna(), 'Text', 'Video')\n",
    "        posts['viewsCount'] = np.nan\n",
    "        \n",
    "        \n",
    "        # In[15]:\n",
    "        \n",
    "        \n",
    "        fb_posts = posts[['facebookUrl', 'post_id', 'pageName', 'url', 'time', 'message', 'likes', 'comments_count', 'reshare_count', 'viewsCount', 'isVideo']]\n",
    "        \n",
    "        fb_posts = fb_posts.rename(columns={\n",
    "        'facebookUrl': 'profile_url',\n",
    "        'post_id': 'id',\n",
    "        'pageName': 'user_name',\n",
    "        'url': 'url',\n",
    "        'time': 'date',\n",
    "        'message': 'text',\n",
    "        'likes': 'likes',\n",
    "        'comments_count': 'comments',\n",
    "        'reshare_count': 'shares',\n",
    "        'viewsCount': 'views',\n",
    "        'isVideo': 'type'    })\n",
    "        \n",
    "    # ### Instagram\n",
    "    \n",
    "    # In[16]:\n",
    "    \n",
    "    \n",
    "    # Instagram Parameters\n",
    "    \n",
    "    inst_max_results = max_results\n",
    "    inst_start_date_posts = start_date_posts\n",
    "    \n",
    "    \n",
    "    # In[17]:\n",
    "    \n",
    "    if inst_profile_names:\n",
    "        starturls = [f\"https://www.instagram.com/{username}\" for username in inst_profile_names]\n",
    "        \n",
    "        run_input = {\n",
    "        \n",
    "            \"directUrls\": starturls,\n",
    "            \"resultsType\": \"posts\",\n",
    "            \"resultsLimit\": inst_max_results,\n",
    "            \"onlyPostsNewerThan\": inst_start_date_posts\n",
    "        }\n",
    "        \n",
    "        # Run the Actor and wait for it to finish\n",
    "        run = apify.actor(\"apify/instagram-scraper\").call(run_input=run_input)\n",
    "        \n",
    "        i = 0\n",
    "        data = {}\n",
    "        for item in apify.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "            data[i] = item\n",
    "            i = i +1\n",
    "        \n",
    "        posts = pd.DataFrame(data).transpose()\n",
    "        inst_posts = posts[['inputUrl', 'id', 'ownerUsername', 'url', 'timestamp', 'caption', 'likesCount', 'commentsCount', 'videoPlayCount', 'type', 'videoDuration']]\n",
    "        \n",
    "        \n",
    "        # In[18]:\n",
    "        \n",
    "        \n",
    "        # Get true username\n",
    "        \n",
    "        inst_posts['ownerUsername'] = inst_posts['inputUrl'].str.extract(r'instagram\\.com/([^/?#]+)')\n",
    "\n",
    "        inst_posts = inst_posts.rename(columns={\n",
    "        'inputUrl': 'profile_url',\n",
    "        'id': 'id',\n",
    "        'ownerUsername': 'user_name',\n",
    "        'url': 'url',\n",
    "        'timestamp': 'date',\n",
    "        'caption': 'text',\n",
    "        'likesCount': 'likes',\n",
    "        'commentsCount': 'comments',\n",
    "        'videoPlayCount': 'views',\n",
    "        'type': 'type',\n",
    "        'videoDuration': 'video_duration'\n",
    "        })\n",
    "    \n",
    "    # ### TikTok\n",
    "    \n",
    "    # In[19]:\n",
    "    \n",
    "    \n",
    "    # TikTok Parameters\n",
    "    \n",
    "    tt_max_results = max_results\n",
    "    tt_past_days = past_days_posts\n",
    "    \n",
    "    \n",
    "    # In[20]:\n",
    "    \n",
    "    if tt_profile_names:\n",
    "        run_input = {\n",
    "        \n",
    "            \"profiles\": tt_profile_names,\n",
    "            \"scrapeLastNDays\": tt_past_days,\n",
    "            \"resultsPerPage\": tt_max_results\n",
    "        \n",
    "        }\n",
    "        \n",
    "        # Run the Actor and wait for it to finish\n",
    "        run = apify.actor(\"clockworks/free-tiktok-scraper\").call(run_input=run_input)\n",
    "        \n",
    "        i = 0\n",
    "        data = {}\n",
    "        for item in apify.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "            data[i] = item\n",
    "            i = i +1\n",
    "        \n",
    "        videos = pd.DataFrame(data).transpose()\n",
    "        videos = videos[videos['createTime'].notna()]\n",
    "        \n",
    "        videos = videos.drop(['musicMeta','mediaUrls'], axis=1)\n",
    "        author_df = pd.json_normalize(videos['authorMeta'])\n",
    "        author_df = author_df.rename(columns=lambda x: 'author_' + x)\n",
    "        video_df = pd.json_normalize(videos['videoMeta'])\n",
    "        video_df = video_df.rename(columns=lambda x: 'video_' + x)\n",
    "        videos = pd.concat([videos.drop(columns=['authorMeta','videoMeta']), author_df,video_df], axis=1)\n",
    "        videos = videos[videos['createTime'].notna()]\n",
    "        videos = videos.rename(columns={\"id\": \"video_id\"})\n",
    "        tt_posts = videos[['author_profileUrl', 'video_id', 'author_name', 'webVideoUrl', 'createTimeISO', 'text', 'diggCount', 'commentCount', 'shareCount', 'playCount', 'collectCount', 'video_duration', 'author_following', 'author_friends', 'author_fans', 'author_heart', 'author_video', 'author_digg']]\n",
    "        tt_posts['type'] = 'video'\n",
    "        \n",
    "        tt_video_list = videos[['webVideoUrl']]['webVideoUrl'].to_list()\n",
    "        \n",
    "        tt_posts = tt_posts.rename(columns={\n",
    "        'author_profileUrl': 'profile_url',\n",
    "        'video_id': 'id',\n",
    "        'author_name': 'user_name',\n",
    "        'webVideoUrl': 'url',\n",
    "        'createTimeISO': 'date',\n",
    "        'text': 'text',\n",
    "        'diggCount': 'likes',\n",
    "        'commentCount': 'comments',\n",
    "        'shareCount': 'shares',\n",
    "        'playCount': 'views',\n",
    "        'collectCount': 'bookmarks',\n",
    "        'video_duration': 'video_duration'\n",
    "        })\n",
    "    # ## Analysis\n",
    "    \n",
    "    # ### Combine into a single dataframe  \n",
    "\n",
    "    available_posts = []\n",
    "\n",
    "    if 'fb_posts' in locals():\n",
    "        available_posts.append(fb_posts)\n",
    "    if 'inst_posts' in locals():\n",
    "        available_posts.append(inst_posts)\n",
    "    if 'tt_posts' in locals():\n",
    "        available_posts.append(tt_posts)\n",
    "\n",
    "    posts = pd.concat(available_posts, ignore_index=True)\n",
    "    \n",
    "    expected_columns = [\n",
    "        'profile_url', 'id', 'user_name', 'url', 'date', 'text',\n",
    "        'likes', 'comments', 'shares', 'views', 'type',\n",
    "        'bookmarks', 'video_duration'\n",
    "    ]\n",
    "\n",
    "    # Keep only the columns that actually exist\n",
    "    posts = posts[[col for col in expected_columns if col in posts.columns]]\n",
    "    \n",
    "    \n",
    "    # In[260]:\n",
    "    \n",
    "    \n",
    "    posts[\"platform\"] = (\n",
    "        posts[\"profile_url\"]\n",
    "          .str.extract(r\"https?://(?:www\\.)?([^/]+)\")   # â†’ 'facebook.com'\n",
    "          [0]                                           # the capture group\n",
    "          .str.split(\".\").str[0]                        # keep 'facebook'\n",
    "          .str.lower()                                  # normalise\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # In[261]:\n",
    "    \n",
    "    \n",
    "    def secs(val):\n",
    "        \"\"\"\n",
    "        Return total seconds or <NA> for anything empty/invalid.\n",
    "        Handles plain-seconds (8, '18') or 'HH:MM:SS'.\n",
    "        \"\"\"\n",
    "        # 1) missings ------------------------------------------------------------\n",
    "        if val is None or (isinstance(val, float) and math.isnan(val)) or pd.isna(val):\n",
    "            return pd.NA\n",
    "    \n",
    "        # 2) already numeric (int / numeric-string) ------------------------------\n",
    "        try:\n",
    "            return int(float(val))\n",
    "        except (ValueError, TypeError):\n",
    "            pass                        # fall through if it isn't plain seconds\n",
    "    \n",
    "        # 3) assume HH:MM:SS (or MM:SS) -----------------------------------------\n",
    "        parts = list(map(int, str(val).split(\":\")))\n",
    "        if len(parts) == 2:             # MM:SS\n",
    "            parts = [0] + parts\n",
    "        h, m, s = parts\n",
    "        return h*3600 + m*60 + s\n",
    "    \n",
    "    # â”€â”€ apply it â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    posts[\"video_duration\"] = posts[\"video_duration\"].apply(secs)\n",
    "    \n",
    "    \n",
    "    # In[262]:\n",
    "    \n",
    "    \n",
    "    posts['date'] = pd.to_datetime(posts['date'], format = 'mixed', utc = True)\n",
    "    posts['type'] = posts['type'].str.title()\n",
    "    posts['platform'] = posts['platform'].str.title()\n",
    "    \n",
    "    \n",
    "    # In[263]:\n",
    "    \n",
    "    \n",
    "    # Lookup Username \n",
    "    posts = posts.rename(columns={'profile_name':'user_name'})\n",
    "    posts['user_name'] = posts['user_name'].str.lower()\n",
    "    posts = posts.merge(lookup_df, on=['platform', 'user_name'], how='left')\n",
    "\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c022695c-0695-4955-94fb-edefd55fa767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report (posts):\n",
    "\n",
    "    import pandas as pd\n",
    "    from apify_client import ApifyClient\n",
    "    import json\n",
    "    pd.options.display.max_columns = None\n",
    "    from datetime import datetime, timedelta, date\n",
    "    from pandas import json_normalize\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sqlalchemy.exc import DatabaseError\n",
    "    from openai import OpenAI, AsyncOpenAI\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas()\n",
    "    from typing import Dict, List\n",
    "    import tiktoken\n",
    "    import nest_asyncio, asyncio\n",
    "    import dateparser\n",
    "    import plotly\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    import matplotlib.ticker as ticker\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    from PIL import Image\n",
    "    from docx import Document\n",
    "    from docx.shared import Inches\n",
    "    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "    from docx.shared import Inches, Pt\n",
    "    from docx.oxml.ns import qn\n",
    "    from docx.oxml import OxmlElement\n",
    "    from docx.enum.table import WD_ALIGN_VERTICAL\n",
    "    from docx.shared import Pt, RGBColor\n",
    "    from io import BytesIO\n",
    "    from docx2pdf import convert\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    from IPython.display import FileLink, HTML, display\n",
    "    from urllib.parse import quote\n",
    "    from pathlib import Path\n",
    "    import pathlib\n",
    "    import base64\n",
    "    \n",
    "    posts = posts\n",
    "    \n",
    "    # ### Number of Posts\n",
    "    \n",
    "    # In[281]:\n",
    "    \n",
    "    \n",
    "    number = posts.pivot_table(index='account_name', columns='platform', aggfunc='count', values='id', margins=True, margins_name='Total')\n",
    "    \n",
    "    \n",
    "    # In[282]:\n",
    "    \n",
    "    \n",
    "    # Drop the 'Total' row and column\n",
    "    data = number.drop(index='Total', columns='Total')\n",
    "    \n",
    "    # Define custom colors in column order\n",
    "    platform_colors = {\n",
    "        'Facebook': '#1877F2',   # Facebook Blue\n",
    "        'Instagram': '#E1306C',  # Instagram Pink\n",
    "        'Tiktok': '#69C9D0'      # TikTok Aqua\n",
    "    }\n",
    "    colors = [platform_colors[col] for col in data.columns]\n",
    "    \n",
    "    # Plot with custom colors\n",
    "    ax = data.plot(kind='bar', stacked=True, figsize=(8, 6), color=colors)\n",
    "    \n",
    "    # Beautify\n",
    "    plt.title('Platform Usage by Brand - Last 2 Weeks')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks(rotation=0, fontsize=10)\n",
    "    plt.ylabel('Number of Posts')\n",
    "    plt.legend(title='Platform', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('plot1.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ### Top Posts\n",
    "    \n",
    "    # In[283]:\n",
    "    \n",
    "    \n",
    "    top_comments = posts.pivot_table(index='account_name', aggfunc='max', values=['comments']).reset_index()\n",
    "    top_comments = top_comments.merge(posts[['comments','url']], how='left', on='comments')\n",
    "    \n",
    "    \n",
    "    # In[284]:\n",
    "    \n",
    "    \n",
    "    top_views = posts.pivot_table(index='account_name', aggfunc='max', values=['views']).reset_index()\n",
    "    top_views = top_views.merge(posts[['views','url']], how='left', on='views')\n",
    "    \n",
    "    \n",
    "    # In[285]:\n",
    "    \n",
    "    \n",
    "    top_shares = posts.pivot_table(index='account_name', aggfunc='max', values=['shares']).reset_index()\n",
    "    top_shares = top_shares.merge(posts[['shares','url']], how='left', on='shares')\n",
    "    \n",
    "    \n",
    "    # In[286]:\n",
    "    \n",
    "    \n",
    "    top = posts.pivot_table(index='account_name', aggfunc='max', values=['comments', 'views', 'shares']).reset_index()\n",
    "    \n",
    "    \n",
    "    # In[287]:\n",
    "    \n",
    "    \n",
    "    # Data setup\n",
    "    top_data = top.set_index('account_name')\n",
    "    left_data = top_data[['comments', 'shares']]\n",
    "    right_data = top_data['views']\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    bar_width = 0.25\n",
    "    index = range(len(top_data))\n",
    "    \n",
    "    # Left axis: comments and shares\n",
    "    ax1.bar([i - bar_width/2 for i in index], left_data['comments'], width=bar_width, label='Comments', color='#66c2a5')\n",
    "    ax1.bar([i + bar_width/2 for i in index], left_data['shares'], width=bar_width, label='Shares', color='#fc8d62')\n",
    "    ax1.set_ylabel('Comments / Shares', fontsize=12)\n",
    "    ax1.set_xticks(index)\n",
    "    ax1.set_xticklabels(top_data.index, rotation=0, fontsize=10)\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    # Right axis: views\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar([i + bar_width*1.5 for i in index], right_data, width=bar_width, label='Views', color='#8da0cb')\n",
    "    ax2.set_ylabel('Views', fontsize=12, color='#8da0cb')\n",
    "    ax2.tick_params(axis='y', labelcolor='#8da0cb')\n",
    "    \n",
    "    # Format y-ticks on right axis to millions\n",
    "    ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x/1_000_000:.1f}M'))\n",
    "    \n",
    "    # Separate legend for views\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    # Final touches\n",
    "    plt.title(\"Top Posts' Engagement - Last 2 Weeks\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "    \n",
    "    fig.savefig('plot2.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ### Video Duration\n",
    "    \n",
    "    # In[288]:\n",
    "    \n",
    "    \n",
    "    temp = posts[posts['video_duration']>0]\n",
    "    duration = temp.pivot_table(index='account_name', values='video_duration', aggfunc=['mean', 'max', 'min', 'count']).reset_index()\n",
    "    \n",
    "    \n",
    "    # In[289]:\n",
    "    \n",
    "    \n",
    "    # Extract values\n",
    "    x = duration['account_name']\n",
    "    means = duration[('mean', 'video_duration')]\n",
    "    mins = duration[('min', 'video_duration')]\n",
    "    maxs = duration[('max', 'video_duration')]\n",
    "    \n",
    "    # Calculate asymmetric error bars\n",
    "    lower_errors = means - mins\n",
    "    upper_errors = maxs - means\n",
    "    asymmetric_errors = [lower_errors, upper_errors]\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.bar(x, means, yerr=asymmetric_errors, capsize=10, color=['#66c2a5', '#fc8d62'])\n",
    "    \n",
    "    # Beautify\n",
    "    ax.set_ylabel('Average Video Duration (s)', fontsize=12)\n",
    "    ax.set_title('Video Duration Summary - Last 2 Weeks', fontsize=14)\n",
    "    ax.set_xticks(range(len(x)))\n",
    "    ax.set_xticklabels(x, rotation=0, fontsize=10)\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig('plot3.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ### Type of Posts\n",
    "    \n",
    "    # In[290]:\n",
    "    \n",
    "    \n",
    "    posttype = posts.pivot_table(index='account_name', columns='type', aggfunc='count', values=['id'], margins=True, margins_name='Total').reset_index()\n",
    "    \n",
    "    \n",
    "    # In[291]:\n",
    "    \n",
    "    \n",
    "    # Flatten MultiIndex columns\n",
    "    posttype.columns = ['_'.join(col).strip() if col[1] else col[0] for col in posttype.columns]\n",
    "    \n",
    "    # Now columns are like: 'account_name', 'id_Image', ..., 'id_Total'\n",
    "    # Prepare data\n",
    "    data = posttype[posttype['account_name'] != 'Total'].copy()\n",
    "    \n",
    "    # Drop id_Total if present\n",
    "    if 'id_Total' in data.columns:\n",
    "        data = data.drop(columns='id_Total')\n",
    "    \n",
    "    # Set account_name as index\n",
    "    data = data.set_index('account_name').fillna(0)\n",
    "    \n",
    "    # Clean column names for display\n",
    "    clean_labels = [col.replace('id_', '') for col in data.columns]\n",
    "    colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3']\n",
    "    \n",
    "    # Function to skip small slice %s\n",
    "    def autopct_format(pct):\n",
    "        return f'{pct:.1f}%' if pct > 5 else ''\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.suptitle('Type of Posts â€“ Last 2 Weeks', fontsize=16, y=1.05)\n",
    "    \n",
    "    for ax, (account, row) in zip(axes, data.iterrows()):\n",
    "        ax.pie(\n",
    "            row,\n",
    "            labels=clean_labels,\n",
    "            autopct=autopct_format,\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            labeldistance=1.1,\n",
    "            wedgeprops={'linewidth': 1, 'edgecolor': 'white'}\n",
    "        )\n",
    "        ax.set_title(account, fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    fig.savefig('plot4.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Done Until Report\")\n",
    "    # ## Create Report\n",
    "    \n",
    "    # In[292]:\n",
    "    \n",
    "    \n",
    "    def df_to_docx_table(doc, df, title=None):\n",
    "        if title:\n",
    "            heading = doc.add_paragraph(title)\n",
    "            heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "            heading.style = 'Heading 2'\n",
    "    \n",
    "        table = doc.add_table(rows=1, cols=len(df.columns))\n",
    "        table.style = 'Table Grid'\n",
    "    \n",
    "        # Header row\n",
    "        hdr_cells = table.rows[0].cells\n",
    "        for i, col in enumerate(df.columns):\n",
    "            hdr_cells[i].text = str(col)\n",
    "    \n",
    "        # Data rows\n",
    "        for index, row in df.iterrows():\n",
    "            row_cells = table.add_row().cells\n",
    "            for i, val in enumerate(row):\n",
    "                row_cells[i].text = str(val)\n",
    "    \n",
    "        doc.add_paragraph()  # Add spacing between tables\n",
    "    \n",
    "    \n",
    "    # In[293]:\n",
    "    \n",
    "    \n",
    "    # Extract the account names (excluding 'Total')\n",
    "    accounts = posts['account_name'].unique()\n",
    "    report_title = f\"Social Media - Last Two Weeks - Basic Report: {accounts[0]} vs {accounts[1]}\"\n",
    "    \n",
    "    # In[295]:\n",
    "    \n",
    "    \n",
    "    # === CREATE WORD DOCUMENT ===\n",
    "    doc = Document()\n",
    "    # Add title as custom paragraph (not using style='Title')\n",
    "    title_paragraph = doc.add_paragraph()\n",
    "    title_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "    \n",
    "    run = title_paragraph.add_run(report_title)\n",
    "    run.font.name = 'Orbitron'\n",
    "    run.font.size = Pt(28)\n",
    "    run.font.bold = True\n",
    "    run.font.color.rgb = RGBColor(0, 0, 0)  # Black\n",
    "    \n",
    "    for _ in range(6):\n",
    "        doc.add_paragraph()\n",
    "    img_path = Path.cwd() / \"Analytics.png\"\n",
    "    doc.add_picture(str(img_path), width=Inches(6))\n",
    "    doc.add_page_break()\n",
    "    \n",
    "    \n",
    "    plot_files = [\n",
    "        ('plot1.png', 'Platform Usage'),\n",
    "        ('plot2.png', 'Engagement Metrics'),\n",
    "        ('plot3.png', 'Video Duration Summary Statistics'),\n",
    "        ('plot4.png', 'Type of Posts')\n",
    "    ]\n",
    "\n",
    "    print(plot_files)\n",
    "    \n",
    "    for i, (plot_file, heading_text) in enumerate(plot_files):\n",
    "        heading_para = doc.add_paragraph()\n",
    "        heading_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "        run = heading_para.add_run(heading_text)\n",
    "        run.font.name = 'Orbitron'\n",
    "        run.font.size = Pt(19)\n",
    "        run.font.bold = True\n",
    "        run.font.color.rgb = RGBColor(187, 20, 26)  # #BB141A\n",
    "    \n",
    "        # Add a full-height table for vertical centering of image only\n",
    "        table = doc.add_table(rows=1, cols=1)\n",
    "        table.allow_autofit = False\n",
    "        cell = table.cell(0, 0)\n",
    "        cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "    \n",
    "        # Set full page height minus a bit for the heading (approx 8 inches)\n",
    "        row = table.rows[0]\n",
    "        row.height = Inches(8)\n",
    "    \n",
    "        # Ensure <w:tblPr> exists\n",
    "        tbl = table._tbl\n",
    "        tbl_pr = tbl.tblPr\n",
    "        if tbl_pr is None:\n",
    "            tbl_pr = OxmlElement('w:tblPr')\n",
    "            tbl.append(tbl_pr)\n",
    "    \n",
    "        tbl_w = OxmlElement('w:tblW')\n",
    "        tbl_w.set(qn('w:w'), '0')\n",
    "        tbl_w.set(qn('w:type'), 'auto')\n",
    "        tbl_pr.append(tbl_w)\n",
    "    \n",
    "        # Add image into the cell\n",
    "        paragraph = cell.paragraphs[0]\n",
    "        run = paragraph.add_run()\n",
    "        run.add_picture(plot_file, width=Inches(6))\n",
    "        paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "    \n",
    "        # Add a page break unless it's the last\n",
    "        if i != len(plot_files) - 1:\n",
    "            doc.add_page_break()\n",
    "\n",
    "    print(\"Done with Graphs in Report\")\n",
    "    \n",
    "    # Add all dataframes on one page\n",
    "    doc.add_page_break()\n",
    "    heading_para = doc.add_paragraph()\n",
    "    heading_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "    run = heading_para.add_run('Underlying Data Tables')\n",
    "    run.font.name = 'Orbitron'\n",
    "    run.font.size = Pt(19)\n",
    "    run.font.bold = True\n",
    "    run.font.color.rgb = RGBColor(187, 20, 26)  # #BB141A\n",
    "\n",
    "    number = number.reset_index()\n",
    "    \n",
    "    df_to_docx_table(doc, number, 'Platform Usage')\n",
    "    df_to_docx_table(doc, top_views, 'Most Viewed Posts')\n",
    "    df_to_docx_table(doc, top_comments, 'Most Commented Posts')\n",
    "    df_to_docx_table(doc, top_shares, 'Most Shared Posts')\n",
    "    df_to_docx_table(doc, top, 'Top Posts')\n",
    "    df_to_docx_table(doc, duration.droplevel(0, axis=1), 'Video Duration Summary')  # if multiindex\n",
    "    df_to_docx_table(doc, posttype, 'Post Type Count')\n",
    "    \n",
    "    # Save Word file\n",
    "    file_name = f\"Social Media - Last Two Weeks - Basic Report - {accounts[0]} vs {accounts[1]}.docx\"\n",
    "    doc.save(file_name)\n",
    "    with open(file_name, \"rb\") as fp:\n",
    "        b64 = base64.b64encode(fp.read()).decode()\n",
    "    \n",
    "    mime = \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    "    html = (f'<a download=\"{file_name}\" '\n",
    "            f'href=\"data:{mime};base64,{b64}\">'\n",
    "            'ðŸ“„â€¯Downloadâ€¯theâ€¯Wordâ€¯report</a>')\n",
    "    display(HTML(html))\n",
    "    #convert(file_name) This only works if you are running the script from a Windows PC with Word installed. Can use a cloud conversion service, but unnecessary at this stage.\n",
    "    \n",
    "    \n",
    "    # In[296]:\n",
    "    \n",
    "    \n",
    "    for file_tuple in plot_files:\n",
    "        filename = file_tuple[0]  # extract just the filename\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95508ce1-4a0e-46bb-a267-970b5c3f228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577e9cbc3f90451dadc89dbcea3a5d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Generate\\u202freport', icon='check', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65065a54158246b2bbd01bf9871be737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid #888', height='200px', overflow='auto'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084e02dd9f144866a40b223d7c4368e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid #888', padding='6px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# ---------- widgets ----------\n",
    "btn_generate = widgets.Button(\n",
    "    description=\"Generateâ€¯report\",\n",
    "    button_style=\"success\",\n",
    "    icon=\"check\"\n",
    ")\n",
    "out_log    = widgets.Output(layout={\"border\": \"1px solid #888\",\n",
    "                                    \"height\": \"200px\",\n",
    "                                    \"overflow\": \"auto\"})\n",
    "out_report = widgets.Output(layout={\"border\": \"1px solid #888\",\n",
    "                                    \"padding\": \"6px\"})\n",
    "\n",
    "# ---------- click handler ----------\n",
    "def _on_click(b):\n",
    "    btn_generate.disabled = True\n",
    "    with out_log:\n",
    "        clear_output()\n",
    "        print(\"Running fetch_data() â€¦\")\n",
    "    try:\n",
    "        posts = fetch_data()                           # â‘ \n",
    "\n",
    "        with out_log:\n",
    "            print(\"âœ…  Data fetched, building report â€¦\")\n",
    "\n",
    "        with out_report:                              # â‘¡ capture all displays\n",
    "            clear_output()\n",
    "            generate_report(posts)                    # build DOCX & show link\n",
    "\n",
    "        with out_log:\n",
    "            print(\"ðŸŽ‰  All done\")\n",
    "    except Exception as e:\n",
    "        with out_log:\n",
    "            print(\"ðŸš«  Error:\", e)\n",
    "            raise\n",
    "    finally:\n",
    "        btn_generate.disabled = False\n",
    "\n",
    "btn_generate.on_click(_on_click)\n",
    "\n",
    "display(btn_generate, out_log, out_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b18d6b-3425-4646-a776-c39b185b34de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
